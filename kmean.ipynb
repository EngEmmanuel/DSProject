{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "from oddt import virtualscreening\n",
    "from oddt.virtualscreening import electroshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dude_target_dict = {\n",
    "    'CAH2': 'CHEMBL205',\n",
    "    'JAK2': 'CHEMBL2971',\n",
    "    'ACES': 'CHEMBL220',\n",
    "    'VGFR2': 'CHEMBL4142',\n",
    "    'BACE1': 'CHEMBL4822',\n",
    "    'EGFR': 'CHEMBL203',\n",
    "    'AA2AR': 'CHEMBL251',\n",
    "    'FA10': 'CHEMBL244'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# digits: 16; # samples: 201318; # features 200\n"
     ]
    }
   ],
   "source": [
    "file_name = '10_dude_data_plus_rdkit_descriptors.csv'\n",
    "df = pd.read_csv(os.path.join('data',file_name)) # ! diff path\n",
    "## select columns of interest\n",
    "### note that for all columns, standard_type='Ki', standard_relation='=', data_validity_comment=NaN, potential_duplicate=0, assay_type='B'\n",
    "col_meta = ['target_chembl_id', 'dude_name', 'active', 'uniquekey']\n",
    "col_features = [d[0] for d in Descriptors.descList]\n",
    "columns = col_meta.copy()\n",
    "columns.extend(col_features)\n",
    "fulldata = df[columns]\n",
    "features = df[col_features].to_numpy()\n",
    "\n",
    "labels = [ str(x) + 'active' for x in dude_target_dict ]\n",
    "labels.extend([ str(x) + 'decoy' for x in dude_target_dict ])\n",
    "labels = np.array(labels)\n",
    "\n",
    "#np.isnan(features).any()\n",
    "#features[ np.isnan(features) ] = 0\n",
    "# Remove rows with nans\n",
    "fulldata = fulldata[~np.isnan(features).any(axis=1)]\n",
    "features = features[~np.isnan(features).any(axis=1)]\n",
    "#np.isinf(features).any()\n",
    "#features[ np.isinf(features) ] = 0\n",
    "# Remove rows with inf\n",
    "fulldata = fulldata[~np.isinf(features).any(axis=1)]\n",
    "features = features[~np.isinf(features).any(axis=1)]\n",
    "\n",
    "(n_samples, n_features), n_digits = features.shape, len(labels)\n",
    "print(\n",
    "    f\"# digits: {n_digits}; # samples: {n_samples}; # features {n_features}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def bench_k_means(kmeans, name, data, labels):\n",
    "    \"\"\"Benchmark to evaluate the KMeans initialization methods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kmeans : KMeans instance\n",
    "        A :class:`~sklearn.cluster.KMeans` instance with the initialization\n",
    "        already set.\n",
    "    name : str\n",
    "        Name given to the strategy. It will be used to show the results in a\n",
    "        table.\n",
    "    data : ndarray of shape (n_samples, n_features)\n",
    "        The data to cluster.\n",
    "    labels : ndarray of shape (n_samples,)\n",
    "        The labels used to compute the clustering metrics which requires some\n",
    "        supervision.\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    estimator = make_pipeline(StandardScaler(), kmeans).fit(data)\n",
    "    fit_time = time() - t0\n",
    "    results = [name, fit_time, estimator[-1].inertia_]\n",
    "\n",
    "    # Define the metrics which require only the true labels and estimator\n",
    "    # labels\n",
    "    clustering_metrics = [\n",
    "        metrics.homogeneity_score,\n",
    "        metrics.completeness_score,\n",
    "        metrics.v_measure_score,\n",
    "        metrics.adjusted_rand_score,\n",
    "        metrics.adjusted_mutual_info_score,\n",
    "    ]\n",
    "    results += [m(labels, estimator[-1].labels_) for m in clustering_metrics]\n",
    "\n",
    "    # The silhouette score requires the full dataset\n",
    "    results += [\n",
    "        metrics.silhouette_score(data, estimator[-1].labels_,\n",
    "                                 metric=\"euclidean\", sample_size=300,)\n",
    "    ]\n",
    "\n",
    "    # Show the results\n",
    "    formatter_result = (\"{:9s}\\t{:.3f}s\\t{:.0f}\\t{:.3f}\\t{:.3f}\"\n",
    "                        \"\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\")\n",
    "    print(formatter_result.format(*results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________\n",
      "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "__________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([13, 13,  5, ...,  5,  5,  5])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(82 * '_')\n",
    "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
    "\n",
    "kmeans = KMeans(init=\"k-means++\", n_clusters=n_digits, n_init=4,\n",
    "                random_state=0)\n",
    "kmeans = kmeans.fit(features)\n",
    "kmeans.labels_\n",
    "\n",
    "\n",
    "print(82 * '_')\n",
    "kmeans.labels_\n",
    "#kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_k_means(kmeans=kmeans, name=\"k-means++\", data=features, labels=labels)\n",
    "\n",
    "kmeans = KMeans(init=\"random\", n_clusters=n_digits, n_init=4, random_state=0)\n",
    "bench_k_means(kmeans=kmeans, name=\"random\", data=features, labels=labels)\n",
    "\n",
    "pca = PCA(n_components=n_digits).fit(data)\n",
    "kmeans = KMeans(init=pca.components_, n_clusters=n_digits, n_init=1)\n",
    "bench_k_means(kmeans=kmeans, name=\"PCA-based\", data=features, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
